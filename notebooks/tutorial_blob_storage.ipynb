{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.9 64-bit ('venv')",
   "display_name": "Python 3.6.9 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "372b0b7ec2deba16ae067aa3df2758e57c96731335b7f57a0616055622e60b0e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Accessing Time Series Datasets\n",
    "The raw time series datasets used in this project are stored with Azure blob storage. This notebook shows an example of how to access the datasets and an overview of the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Datasets\n",
    "\n",
    "### M4\n",
    "* Stored as train and test csv files ogether with a csv file of metadata. The data is downloaded from the M4 repository on github <https://github.com/Mcompetitions/M4-methods>.\n",
    "* Each line in the files are a distinct time series and the index of a specific time series is the same in the train and test files.\n",
    "* Time series are grouped in files by frequency.\n",
    "* Frequencies are:\n",
    "    * Yearly\n",
    "    * Quarterly\n",
    "    * Monthly\n",
    "    * Weekly\n",
    "    * Daily\n",
    "    * Hourly\n",
    "### FRED\n",
    "* The time series are stored in JSON files with 2000 time series in each file.\n",
    "* Metadata for the time series are stored in files meta_xxxx.json.\n",
    "* Time series observations are stored in files raw_xxxx.json.\n",
    "* The data is collected from the Federal Reserve Economic Data database <https://fred.stlouisfed.org/>.\n",
    "* It is collected using the `fred` pythion api.\n",
    "* Frequencies are:\n",
    "    * Yearly\n",
    "    * Quarterly\n",
    "    * Monthly\n",
    "    * Weekly\n",
    "    * Daily"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Access\n",
    "Access to the datasets does not at this point require access keys. The blob storage containers are set to public read access. To access the data you can use the python api."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Azure Blob storage v12.5.0\n"
    }
   ],
   "source": [
    "import os\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, __version__\n",
    "\n",
    "try:\n",
    "    print(\"Azure Blob storage v\" + __version__)\n",
    "    # Quick start code goes here\n",
    "except Exception as ex:\n",
    "    print('Exception:')\n",
    "    print(ex)"
   ]
  },
  {
   "source": [
    "### FRED metadata"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Name of blob: meta_000000.json\nNumber of samples in file: 2001\n\nExample of metadata for a time series: \ncategory_name: New England Textile Industry, 1815-1860\nfrequency: Annual\nfrequency_short: A\ngroup_popularity: 2\nid: CPNEAMOSKEAGI\nlast_updated: 2019-11-01 13:43:55-05\nnode_id: 33934\nnotes: Data were gathered by the authors from various textile collections deposited at various museums and libraries on the East Coast, and collected from the original business records of textile mills in New England wherever possible. Preference was given to records that were complete and continuous for long periods, and reasonably intelligible.\n\nReporting techniques differed greatly from mill to mill. To make the data comparable, each mill&#39;s output was allocated uniformly over the months covered by the accounting period. The monthly figures were then summed to calendar years.\n\nMore details about the data are available in the book chapter &quot;The New England Textile Industry, 1825-60: Trends and Fluctuations&quot; (https://www.nber.org/chapters/c1569.pdf).\nobservation_end: 1847-01-01\nobservation_start: 1837-01-01\nparent_id: 33060\npopularity: 2\nrealtime_end: 2020-10-02\nrealtime_start: 2020-10-02\nseasonal_adjustment: Not Seasonally Adjusted\nseasonal_adjustment_short: NSA\nsource: FRED\ntitle: Cotton Production by Amoskeag I Mill\nunits: Thousands of Yards\nunits_short: Thous. of Yards\n"
    }
   ],
   "source": [
    "container_client = ContainerClient(account_url=\"https://tsdatasets.blob.core.windows.net/\", container_name=\"fred\")\n",
    "all_blobs = container_client.list_blobs()\n",
    "for b in all_blobs:\n",
    "    bname = b[\"name\"]\n",
    "    print(f\"Name of blob: {bname}\")\n",
    "    blob_client = BlobClient(account_url=\"https://tsdatasets.blob.core.windows.net/\", container_name=\"fred\", blob_name=bname)\n",
    "    with open(bname, \"wb\") as my_blob:\n",
    "        download_stream = blob_client.download_blob()\n",
    "        my_blob.write(download_stream.readall())\n",
    "        my_blob.close()\n",
    "    break\n",
    "with open(bname, \"rb\") as fp:\n",
    "    blob_json = json.load(fp)\n",
    "    fp.close()\n",
    "print(f\"Number of samples in file: {len(blob_json)}\\n\")\n",
    "print(\"Example of metadata for a time series:\\n\")\n",
    "for key, value in blob_json[1].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "source": [
    "### FRED observations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Name of blob: raw_000000.json\nNumber of samples in file: 2001\ncategory_name: New England Textile Industry, 1815-1860\nfrequency: Annual\nid: CPNEAMOSKEAGI\nnode_id: 33934\nobservations: [{&#39;date&#39;: &#39;1837-01-01&#39;, &#39;value&#39;: &#39;1272.0&#39;}, {&#39;date&#39;: &#39;1838-01-01&#39;, &#39;value&#39;: &#39;1407.0&#39;}, {&#39;date&#39;: &#39;1839-01-01&#39;, &#39;value&#39;: &#39;1453.0&#39;}, {&#39;date&#39;: &#39;1840-01-01&#39;, &#39;value&#39;: &#39;1126.0&#39;}, {&#39;date&#39;: &#39;1841-01-01&#39;, &#39;value&#39;: &#39;1077.0&#39;}, {&#39;date&#39;: &#39;1842-01-01&#39;, &#39;value&#39;: &#39;1102.0&#39;}, {&#39;date&#39;: &#39;1843-01-01&#39;, &#39;value&#39;: &#39;1148.0&#39;}, {&#39;date&#39;: &#39;1844-01-01&#39;, &#39;value&#39;: &#39;1160.0&#39;}, {&#39;date&#39;: &#39;1845-01-01&#39;, &#39;value&#39;: &#39;1189.0&#39;}, {&#39;date&#39;: &#39;1846-01-01&#39;, &#39;value&#39;: &#39;1190.0&#39;}, {&#39;date&#39;: &#39;1847-01-01&#39;, &#39;value&#39;: &#39;540.0&#39;}]\nparent_id: 33060\nsource: FRED\n"
    }
   ],
   "source": [
    "bname = \"raw_000000.json\"\n",
    "print(f\"Name of blob: {bname}\")\n",
    "blob_client = BlobClient(account_url=\"https://tsdatasets.blob.core.windows.net/\", container_name=\"fred\", blob_name=bname)\n",
    "with open(bname, \"wb\") as my_blob:\n",
    "    download_stream = blob_client.download_blob()\n",
    "    my_blob.write(download_stream.readall())\n",
    "    my_blob.close()\n",
    "with open(bname, \"rb\") as fp:\n",
    "    blob_json = json.load(fp)\n",
    "    fp.close()\n",
    "print(f\"Number of samples in file: {len(blob_json)}\")\n",
    "for key, value in blob_json[1].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "source": [
    "### M4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Name of blob: Daily-test.csv\nName of blob: Daily-train.csv\nName of blob: Hourly-test.csv\nName of blob: Hourly-train.csv\nName of blob: Monthly-test.csv\nName of blob: Monthly-train.csv\nName of blob: Quarterly-test.csv\nName of blob: Quarterly-train.csv\nName of blob: Weekly-test.csv\nName of blob: Weekly-train.csv\nName of blob: Yearly-test.csv\nName of blob: Yearly-train.csv\n\nDownloading Yearly-train.csv\n   V1      V2      V3      V4      V5      V6      V7      V8      V9     V10  \\\n0  Y1  5172.1  5133.5  5186.9  5084.6  5182.0  5414.3  5576.2  5752.9  5955.2   \n1  Y2  2070.0  2104.0  2394.0  1651.0  1492.0  1348.0  1198.0  1192.0  1105.0   \n2  Y3  2760.0  2980.0  3200.0  3450.0  3670.0  3850.0  4000.0  4160.0  4290.0   \n3  Y4  3380.0  3670.0  3960.0  4190.0  4440.0  4700.0  4890.0  5060.0  5200.0   \n4  Y5  1980.0  2030.0  2220.0  2530.0  2610.0  2720.0  2970.0  2980.0  3100.0   \n\n   ...  V827  V828  V829  V830  V831  V832  V833  V834  V835  V836  \n0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n1  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n2  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n3  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n4  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n\n[5 rows x 836 columns]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "container_client = ContainerClient(account_url=\"https://tsdatasets.blob.core.windows.net/\", container_name=\"mfour\")\n",
    "all_blobs = container_client.list_blobs()\n",
    "for b in all_blobs:\n",
    "    bname = b[\"name\"]\n",
    "    print(f\"Name of blob: {bname}\")\n",
    "print(f\"\\nDownloading {bname}\")\n",
    "blob_client = BlobClient(account_url=\"https://tsdatasets.blob.core.windows.net/\", container_name=\"mfour\", blob_name=bname)\n",
    "\n",
    "with open(bname, \"wb\") as my_blob:\n",
    "    download_stream = blob_client.download_blob()\n",
    "    my_blob.write(download_stream.readall())\n",
    "    my_blob.close()\n",
    "\n",
    "df = pd.read_csv(bname)\n",
    "print(df.head())"
   ]
  }
 ]
}